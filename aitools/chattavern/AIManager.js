/**
 * AIç®¡ç†å™¨ - è´Ÿè´£è°ƒç”¨å„ç§LLM API
 * æ”¯æŒOpenAIã€Claudeç­‰ä¸»æµAIæœåŠ¡
 * é‡æ„ç‰ˆï¼šä½¿ç”¨LLMClientç»Ÿä¸€å°è£…ï¼Œæ¶ˆé™¤ä»£ç é‡å¤
 */
class AIManager {
    constructor() {
        this.config = this.loadConfig();
        this.llmClient = null;  // LLMå®¢æˆ·ç«¯å®ä¾‹
    }

    /**
     * ä»localStorageåŠ è½½é…ç½®
     */
    loadConfig() {
        const saved = localStorage.getItem('chattavern_ai_config');
        const defaultConfig = {
            provider: 'custom',  // ä½¿ç”¨custom providerä»¥æ”¯æŒä»»ä½•OpenAIå…¼å®¹API
            apiKey: '',  // ç©ºå­—ç¬¦ä¸²ï¼Œå¼ºåˆ¶ç”¨æˆ·é…ç½®
            model: 'gpt-3.5-turbo',
            apiUrl: '',
            temperature: 0.9,  // è§’è‰²æ‰®æ¼”å»ºè®®ä½¿ç”¨è¾ƒé«˜çš„temperature
            maxTokens: 4000,   // å¢å¤§é»˜è®¤å€¼ï¼Œæ”¯æŒæ›´é•¿çš„å›å¤
            enabled: true
        };

        if (saved) {
            try {
                return { ...defaultConfig, ...JSON.parse(saved) };
            } catch (error) {
                console.error('[AIManager] é…ç½®åŠ è½½å¤±è´¥:', error);
                return defaultConfig;
            }
        }

        return defaultConfig;
    }

    /**
     * ä¿å­˜é…ç½®
     */
    saveConfig(newConfig) {
        this.config = { ...this.config, ...newConfig };
        localStorage.setItem('chattavern_ai_config', JSON.stringify(this.config));
        console.log('[AIManager] é…ç½®å·²ä¿å­˜:', this.config);

        // æ¸…ç©ºLLMå®¢æˆ·ç«¯å®ä¾‹ï¼Œä¸‹æ¬¡è°ƒç”¨æ—¶ä¼šé‡æ–°åˆ›å»º
        this.llmClient = null;
    }

    /**
     * æ£€æŸ¥AIæ˜¯å¦å¯ç”¨
     */
    async isAvailable() {
        return this.config.enabled && this.config.apiKey && this.config.apiKey.length > 0;
    }

    /**
     * åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
     */
    async initializeLLMClient() {
        if (this.llmClient) {
            return this.llmClient;
        }

        // åŠ¨æ€å¯¼å…¥LLMClient
        const { LLMClient } = await import('../aichat/llm-client.js');

        this.llmClient = LLMClient.createFromConfig({
            apiKey: this.config.apiKey,
            baseUrl: this.config.apiUrl,
            model: this.config.model,
            simulateBrowser: true  // å¯ç”¨æµè§ˆå™¨æ¨¡æ‹Ÿï¼Œç»•è¿‡Cloudflare
        });

        console.log('[AIManager] LLMClientå·²åˆå§‹åŒ–');
        return this.llmClient;
    }

    /**
     * è·å–AIå›å¤
     * @param {string} characterId è§’è‰²ID
     * @param {string} userMessage ç”¨æˆ·æ¶ˆæ¯
     * @param {Array} context å¯¹è¯ä¸Šä¸‹æ–‡
     * @param {Object} character è§’è‰²å¡å¯¹è±¡
     */
    async getResponse(characterId, userMessage, context, character) {
        if (!await this.isAvailable()) {
            throw new Error('AIæœªé…ç½®æˆ–æœªå¯ç”¨');
        }

        console.log('[AIManager] å¼€å§‹è·å–AIå›å¤');
        console.log('[AIManager] ä½¿ç”¨æä¾›å•†:', this.config.provider);
        console.log('[AIManager] æ¨¡å‹:', this.config.model);

        try {
            let response;

            switch (this.config.provider) {
                case 'openai':
                case 'deepseek':
                case 'custom':
                    // OpenAIå…¼å®¹APIç»Ÿä¸€ä½¿ç”¨LLMClient
                    response = await this.callOpenAI(userMessage, context, character);
                    break;
                case 'claude':
                    // Claude APIæ ¼å¼ä¸åŒï¼Œä¿ç•™ç‹¬ç«‹å®ç°
                    response = await this.callClaude(userMessage, context, character);
                    break;
                default:
                    throw new Error('ä¸æ”¯æŒçš„AIæä¾›å•†: ' + this.config.provider);
            }

            console.log('[AIManager] AIå›å¤æˆåŠŸ:', response.substring(0, 50) + '...');
            return response;

        } catch (error) {
            console.error('[AIManager] AIè°ƒç”¨å¤±è´¥:', error);
            throw error;
        }
    }

    /**
     * è°ƒç”¨OpenAI APIï¼ˆä½¿ç”¨LLMClientç»Ÿä¸€å°è£…ï¼‰
     * é‡æ„ç‰ˆï¼šåˆ é™¤çº¦150è¡Œé‡å¤ä»£ç ï¼Œä½¿ç”¨LLMClient.stream()
     */
    async callOpenAI(userMessage, context, character) {
        // ç¡®ä¿LLMå®¢æˆ·ç«¯å·²åˆå§‹åŒ–
        await this.initializeLLMClient();

        // æ„å»ºæ¶ˆæ¯æ•°ç»„
        const messages = [];

        // ç³»ç»Ÿæç¤ºè¯ï¼ˆè§’è‰²è®¾å®šï¼‰
        if (character) {
            const systemPrompt = character.getSystemPrompt();
            messages.push({
                role: 'system',
                content: systemPrompt
            });
        }

        // å¯¹è¯å†å²ï¼ˆæœ€è¿‘çš„å‡ æ¡ï¼‰
        if (context && context.length > 0) {
            context.forEach(msg => {
                messages.push({
                    role: msg.role === 'user' ? 'user' : 'assistant',
                    content: msg.content
                });
            });
        }

        // å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.push({
            role: 'user',
            content: userMessage
        });

        console.log('[AIManager] ========== APIè¯·æ±‚è¯¦æƒ… ==========');
        console.log('[AIManager] ä½¿ç”¨LLMClientç»Ÿä¸€å°è£…');
        console.log('[AIManager] æ¨¡å‹:', this.config.model);
        console.log('[AIManager] æ¶ˆæ¯æ•°é‡:', messages.length);
        console.log('[AIManager] Temperature:', character?.temperature || this.config.temperature);
        console.log('[AIManager] Max Tokens:', character?.max_tokens || this.config.maxTokens);

        try {
            // ä½¿ç”¨LLMClientçš„æµå¼æ”¶é›†æ–¹æ³•
            const result = await this.llmClient.streamAndCollect(messages, {
                timeout: 120,  // è¶…æ—¶120ç§’
                temperature: character?.temperature || this.config.temperature,
                maxTokens: character?.max_tokens || this.config.maxTokens,
                maxRetries: 2  // æœ€å¤šé‡è¯•2æ¬¡
            });

            console.log('[AIManager] è¯·æ±‚æˆåŠŸ');
            console.log('[AIManager] è¿”å›å†…å®¹é•¿åº¦:', result.content.length);
            console.log('[AIManager] Chunksæ•°é‡:', result.chunkCount);

            // å¦‚æœæœ‰reasoningå†…å®¹ï¼ˆDeepSeek R1ç­‰ï¼‰ï¼Œè®°å½•åˆ°æ—¥å¿—
            if (result.reasoning) {
                console.log('[AIManager] Reasoningé•¿åº¦:', result.reasoning.length);
            }

            return result.content;

        } catch (error) {
            console.error('[AIManager] ========== è¯·æ±‚å¤±è´¥è¯¦æƒ… ==========');
            console.error('[AIManager] é”™è¯¯ä¿¡æ¯:', error.message);

            // LLMClientå·²ç»å¤„ç†äº†å¤§éƒ¨åˆ†é”™è¯¯ï¼Œè¿™é‡Œåªéœ€è¦æ·»åŠ ç‰¹å®šçš„æç¤º
            if (error.message.includes('ç½‘ç»œè¿æ¥å¤±è´¥')) {
                throw new Error(`âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼ˆCORSè·¨åŸŸé—®é¢˜ï¼‰

å¯èƒ½çš„åŸå› ï¼š
1. APIæœåŠ¡å™¨æœªé…ç½®CORSå…è®¸è·¨åŸŸè®¿é—®
2. è¯·æ±‚çš„URLï¼š${this.config.apiUrl || '(æœªè®¾ç½®)'}

ğŸ”§ New APIè§£å†³æ–¹æ¡ˆï¼š
åœ¨docker runå‘½ä»¤ä¸­æ·»åŠ ç¯å¢ƒå˜é‡ï¼š
-e ALLOWED_ORIGIN="*"

æˆ–åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ ï¼š
ALLOWED_ORIGIN=*

è¯¦ç»†é”™è¯¯: ${error.message}`);
            }

            throw error;
        }
    }

    /**
     * è°ƒç”¨Claude API
     * ä¿ç•™ç‹¬ç«‹å®ç°ï¼Œå› ä¸ºClaude APIæ ¼å¼ä¸OpenAIä¸åŒ
     */
    async callClaude(userMessage, context, character) {
        const apiUrl = this.config.apiUrl || 'https://api.anthropic.com/v1/messages';

        // æ„å»ºæ¶ˆæ¯æ•°ç»„
        const messages = [];

        // Claudeçš„systemå‚æ•°æ˜¯ç‹¬ç«‹çš„ï¼Œä¸åœ¨messagesæ•°ç»„ä¸­
        let systemPrompt = '';
        if (character) {
            systemPrompt = character.getSystemPrompt();
        }

        // å¯¹è¯å†å²
        if (context && context.length > 0) {
            context.forEach(msg => {
                messages.push({
                    role: msg.role === 'user' ? 'user' : 'assistant',
                    content: msg.content
                });
            });
        }

        // å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.push({
            role: 'user',
            content: userMessage
        });

        console.log('[AIManager] Claudeè¯·æ±‚æ¶ˆæ¯æ•°:', messages.length);

        const requestBody = {
            model: this.config.model || 'claude-3-sonnet-20240229',
            max_tokens: character?.max_tokens || this.config.maxTokens,
            temperature: character?.temperature || this.config.temperature,
            messages: messages
        };

        // æ·»åŠ ç³»ç»Ÿæç¤ºè¯
        if (systemPrompt) {
            requestBody.system = systemPrompt;
        }

        const response = await fetch(apiUrl, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'x-api-key': this.config.apiKey,
                'anthropic-version': '2023-06-01'
            },
            body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            throw new Error(`Claude APIé”™è¯¯: ${response.status} - ${errorData.error?.message || response.statusText}`);
        }

        const data = await response.json();
        return data.content[0].text;
    }

    /**
     * è·å–å½“å‰é…ç½®ï¼ˆç”¨äºUIæ˜¾ç¤ºï¼‰
     */
    getConfig() {
        return { ...this.config };
    }

    /**
     * æµ‹è¯•APIè¿æ¥
     */
    async testConnection() {
        if (!this.config.apiKey) {
            return { success: false, message: 'è¯·å…ˆè¾“å…¥API Key' };
        }

        try {
            console.log('[AIManager] æµ‹è¯•APIè¿æ¥...');

            const testMessage = 'ä½ å¥½';
            const testContext = [];
            const testCharacter = {
                getSystemPrompt: () => 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹',
                temperature: this.config.temperature,
                max_tokens: 100  // æµ‹è¯•æ—¶ä½¿ç”¨å°‘é‡tokenä»¥èŠ‚çœæˆæœ¬
            };

            await this.getResponse('test', testMessage, testContext, testCharacter);

            return { success: true, message: 'APIè¿æ¥æˆåŠŸï¼' };

        } catch (error) {
            console.error('[AIManager] æµ‹è¯•å¤±è´¥:', error);
            return { success: false, message: error.message };
        }
    }
}

// å…¨å±€å®ä¾‹
if (typeof window !== 'undefined') {
    window.AIManager = AIManager;
}
